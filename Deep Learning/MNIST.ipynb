{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-jAJuH9BXu-I"
      },
      "source": [
        "# MNIST with SciKit-Learn and skorch\n",
        "\n",
        "This notebooks shows how to define and train a simple Neural-Network with PyTorch and use it via skorch with SciKit-Learn.\n",
        "\n",
        "<table align=\"left\"><td>\n",
        "<a target=\"_blank\" href=\"https://colab.research.google.com/github/skorch-dev/skorch/blob/master/notebooks/MNIST.ipynb\">\n",
        "    <img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>  \n",
        "</td><td>\n",
        "<a target=\"_blank\" href=\"https://github.com/skorch-dev/skorch/blob/master/notebooks/MNIST.ipynb\"><img width=32px src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a></td></table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HwRiqVn3Xu-N"
      },
      "source": [
        "**Note**: If you are running this in [a colab notebook](https://colab.research.google.com/github/skorch-dev/skorch/blob/master/notebooks/MNIST.ipynb), we recommend you enable a free GPU by going:\n",
        "\n",
        "> **Runtime**   →   **Change runtime type**   →   **Hardware Accelerator: GPU**\n",
        "\n",
        "If you are running in colab, you should install the dependencies and download the dataset by running the following cell:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GmYbxmOrXu-O",
        "outputId": "9dfff1ae-ea5f-4a6c-dea1-d56108c4f42d"
      },
      "outputs": [],
      "source": [
        "# ! [ ! -z \"$COLAB_GPU\" ] && pip install torch scikit-learn==0.20.* skorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pqPmZCxMXu-P",
        "outputId": "e60abf29-77fc-483f-e4c2-0f2ed435a0bf"
      },
      "outputs": [],
      "source": [
        "from turtle import pd\n",
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BLv9ONppXu-P"
      },
      "source": [
        "## Loading Data\n",
        "Using SciKit-Learns ```fetch_openml``` to load MNIST data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "WWlXeTypXu-Q"
      },
      "outputs": [],
      "source": [
        "mnist = fetch_openml('mnist_784', cache=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jCthA8QTXu-Q",
        "outputId": "cc0ee2f4-1adc-419e-b31a-d4a213e71f49"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(70000, 784)"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "mnist.data.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gyaYNlF8Xu-R"
      },
      "source": [
        "## Preprocessing Data\n",
        "\n",
        "Each image of the MNIST dataset is encoded in a 784 dimensional vector, representing a 28 x 28 pixel image. Each pixel has a value between 0 and 255, corresponding to the grey-value of a pixel.<br />\n",
        "The above ```featch_mldata``` method to load MNIST returns ```data``` and ```target``` as ```uint8``` which we convert to ```float32``` and ```int64``` respectively."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "bAsCGYTAXu-S"
      },
      "outputs": [],
      "source": [
        "X = mnist.data.astype('float32')\n",
        "y = mnist.target.astype('int64')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'numpy.ndarray'>\n"
          ]
        }
      ],
      "source": [
        "# X=pd.DataFrame.to_numpy(X)\n",
        "print(type(X))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3uYCjaGKXu-S"
      },
      "source": [
        "To avoid big weights that deal with the pixel values from between [0, 255], we scale `X` down. A commonly used range is [0, 1]."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "pyRAdfZbXu-T"
      },
      "outputs": [],
      "source": [
        "X /= 255.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OhwT72v0Xu-T",
        "outputId": "82962a37-e511-46b1-f12d-e3aeb7a8de8f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(0.0, 0.003921569)"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X.min(), X.max()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4esI_QbNXu-T"
      },
      "source": [
        "Note: data is not normalized."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "2duQOjJ-Xu-T"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "wjG6rDH6Xu-U"
      },
      "outputs": [],
      "source": [
        "assert(X_train.shape[0] + X_test.shape[0] == mnist.data.shape[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HUj5vOf8Xu-U",
        "outputId": "7e05c15f-2ea3-45d1-f40f-31cc3a96b1c7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((52500, 784), (52500,))"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train.shape, y_train.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LZi2uFwSXu-U"
      },
      "source": [
        "### Print a selection of training images and their labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "uY3Q5hlAXu-V"
      },
      "outputs": [],
      "source": [
        "def plot_example(X, y):\n",
        "    \"\"\"Plot the first 5 images and their labels in a row.\"\"\"\n",
        "    for i, (img, y) in enumerate(zip(X[:5].reshape(5, 28, 28), y[:5])):\n",
        "        plt.subplot(151 + i)\n",
        "        plt.imshow(img)\n",
        "        plt.xticks([])\n",
        "        plt.yticks([])\n",
        "        plt.title(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "id": "fJGpakRvXu-V",
        "outputId": "c5ba7066-9c4f-4404-f87c-8cdcc233539c"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 5 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plot_example(X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rxQnvn4vXu-V"
      },
      "source": [
        "## Build Neural Network with PyTorch\n",
        "Simple, fully connected neural network with one hidden layer. Input layer has 784 dimensions (28x28), hidden layer has 98 (= 784 / 8) and output layer 10 neurons, representing digits 0 - 9."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "0OvFO1VYXu-V"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/homebrew/Caskroom/miniforge/base/envs/test_env/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "tsqEMtIpXu-W"
      },
      "outputs": [],
      "source": [
        "device = 'mps'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "R40KisVHXu-W"
      },
      "outputs": [],
      "source": [
        "mnist_dim = X.shape[1]\n",
        "hidden_dim = int(mnist_dim/8)\n",
        "output_dim = len(np.unique(mnist.target))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "prygWvUZXu-W",
        "outputId": "fc7bcc12-082b-46be-a3dd-09e84a3533e1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(784, 98, 10)"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "mnist_dim, hidden_dim, output_dim"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fCZXhiuDXu-W"
      },
      "source": [
        "A Neural network in PyTorch's framework."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "A3aLdc9SXu-X"
      },
      "outputs": [],
      "source": [
        "class ClassifierModule(nn.Module):\n",
        "    def __init__(\n",
        "            self,\n",
        "            input_dim=mnist_dim,\n",
        "            hidden_dim=hidden_dim,\n",
        "            output_dim=output_dim,\n",
        "            dropout=0.5,\n",
        "    ):\n",
        "        super(ClassifierModule, self).__init__()\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "        self.hidden = nn.Linear(input_dim, hidden_dim)\n",
        "        self.output = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "    def forward(self, X, **kwargs):\n",
        "        X = F.relu(self.hidden(X))\n",
        "        X = self.dropout(X)\n",
        "        X = F.softmax(self.output(X), dim=-1)\n",
        "        return X"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kaJSPOKmXu-X"
      },
      "source": [
        "skorch allows to use PyTorch's networks in the SciKit-Learn setting:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "s0QFlQ63Xu-X"
      },
      "outputs": [],
      "source": [
        "from skorch import NeuralNetClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "45p_YhHJXu-X"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(0)\n",
        "\n",
        "net = NeuralNetClassifier(\n",
        "    ClassifierModule,\n",
        "    max_epochs=20,\n",
        "    lr=0.1,\n",
        "    device=device,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Np6oB1QXu-X",
        "outputId": "3ee38446-fc9e-452b-94c1-b39b53fd9acc"
      },
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "can't convert mps:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32m/Users/adikondepudi/Downloads/MNIST.ipynb Cell 31\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/adikondepudi/Downloads/MNIST.ipynb#X42sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m net\u001b[39m.\u001b[39;49mfit(X_train, y_train)\n",
            "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/test_env/lib/python3.8/site-packages/skorch/classifier.py:141\u001b[0m, in \u001b[0;36mNeuralNetClassifier.fit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[39m\"\"\"See ``NeuralNet.fit``.\u001b[39;00m\n\u001b[1;32m    131\u001b[0m \n\u001b[1;32m    132\u001b[0m \u001b[39mIn contrast to ``NeuralNet.fit``, ``y`` is non-optional to\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    136\u001b[0m \n\u001b[1;32m    137\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    138\u001b[0m \u001b[39m# pylint: disable=useless-super-delegation\u001b[39;00m\n\u001b[1;32m    139\u001b[0m \u001b[39m# this is actually a pylint bug:\u001b[39;00m\n\u001b[1;32m    140\u001b[0m \u001b[39m# https://github.com/PyCQA/pylint/issues/1085\u001b[39;00m\n\u001b[0;32m--> 141\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m(NeuralNetClassifier, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49mfit(X, y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params)\n",
            "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/test_env/lib/python3.8/site-packages/skorch/net.py:1215\u001b[0m, in \u001b[0;36mNeuralNet.fit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m   1212\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwarm_start \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minitialized_:\n\u001b[1;32m   1213\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minitialize()\n\u001b[0;32m-> 1215\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpartial_fit(X, y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params)\n\u001b[1;32m   1216\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
            "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/test_env/lib/python3.8/site-packages/skorch/net.py:1174\u001b[0m, in \u001b[0;36mNeuralNet.partial_fit\u001b[0;34m(self, X, y, classes, **fit_params)\u001b[0m\n\u001b[1;32m   1172\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnotify(\u001b[39m'\u001b[39m\u001b[39mon_train_begin\u001b[39m\u001b[39m'\u001b[39m, X\u001b[39m=\u001b[39mX, y\u001b[39m=\u001b[39my)\n\u001b[1;32m   1173\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1174\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfit_loop(X, y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params)\n\u001b[1;32m   1175\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyboardInterrupt\u001b[39;00m:\n\u001b[1;32m   1176\u001b[0m     \u001b[39mpass\u001b[39;00m\n",
            "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/test_env/lib/python3.8/site-packages/skorch/net.py:1093\u001b[0m, in \u001b[0;36mNeuralNet.fit_loop\u001b[0;34m(self, X, y, epochs, **fit_params)\u001b[0m\n\u001b[1;32m   1087\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrun_single_epoch(dataset_train, training\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, prefix\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1088\u001b[0m                           step_fn\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrain_step, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[1;32m   1090\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrun_single_epoch(dataset_valid, training\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, prefix\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mvalid\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1091\u001b[0m                           step_fn\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvalidation_step, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[0;32m-> 1093\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnotify(\u001b[39m\"\u001b[39;49m\u001b[39mon_epoch_end\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mon_epoch_kwargs)\n\u001b[1;32m   1094\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
            "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/test_env/lib/python3.8/site-packages/skorch/net.py:359\u001b[0m, in \u001b[0;36mNeuralNet.notify\u001b[0;34m(self, method_name, **cb_kwargs)\u001b[0m\n\u001b[1;32m    357\u001b[0m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m, method_name)(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcb_kwargs)\n\u001b[1;32m    358\u001b[0m \u001b[39mfor\u001b[39;00m _, cb \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallbacks_:\n\u001b[0;32m--> 359\u001b[0m     \u001b[39mgetattr\u001b[39;49m(cb, method_name)(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mcb_kwargs)\n",
            "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/test_env/lib/python3.8/site-packages/skorch/callbacks/scoring.py:472\u001b[0m, in \u001b[0;36mEpochScoring.on_epoch_end\u001b[0;34m(self, net, dataset_train, dataset_valid, **kwargs)\u001b[0m\n\u001b[1;32m    469\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m    471\u001b[0m \u001b[39mwith\u001b[39;00m _cache_net_forward_iter(net, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39muse_caching, y_pred) \u001b[39mas\u001b[39;00m cached_net:\n\u001b[0;32m--> 472\u001b[0m     current_score \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_scoring(cached_net, X_test, y_test)\n\u001b[1;32m    474\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_record_score(net\u001b[39m.\u001b[39mhistory, current_score)\n",
            "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/test_env/lib/python3.8/site-packages/skorch/callbacks/scoring.py:180\u001b[0m, in \u001b[0;36mScoringBase._scoring\u001b[0;34m(self, net, X_test, y_test)\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[39m\"\"\"Resolve scoring and apply it to data. Use cached prediction\u001b[39;00m\n\u001b[1;32m    178\u001b[0m \u001b[39minstead of running inference again, if available.\"\"\"\u001b[39;00m\n\u001b[1;32m    179\u001b[0m scorer \u001b[39m=\u001b[39m check_scoring(net, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscoring_)\n\u001b[0;32m--> 180\u001b[0m \u001b[39mreturn\u001b[39;00m scorer(net, X_test, y_test)\n",
            "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/test_env/lib/python3.8/site-packages/sklearn/metrics/_scorer.py:219\u001b[0m, in \u001b[0;36m_BaseScorer.__call__\u001b[0;34m(self, estimator, X, y_true, sample_weight)\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, estimator, X, y_true, sample_weight\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    197\u001b[0m     \u001b[39m\"\"\"Evaluate predicted target values for X relative to y_true.\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \n\u001b[1;32m    199\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[39m        Score function applied to prediction of estimator on X.\u001b[39;00m\n\u001b[1;32m    218\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 219\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_score(\n\u001b[1;32m    220\u001b[0m         partial(_cached_call, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m    221\u001b[0m         estimator,\n\u001b[1;32m    222\u001b[0m         X,\n\u001b[1;32m    223\u001b[0m         y_true,\n\u001b[1;32m    224\u001b[0m         sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[1;32m    225\u001b[0m     )\n",
            "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/test_env/lib/python3.8/site-packages/sklearn/metrics/_scorer.py:261\u001b[0m, in \u001b[0;36m_PredictScorer._score\u001b[0;34m(self, method_caller, estimator, X, y_true, sample_weight)\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_score\u001b[39m(\u001b[39mself\u001b[39m, method_caller, estimator, X, y_true, sample_weight\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    234\u001b[0m     \u001b[39m\"\"\"Evaluate predicted target values for X relative to y_true.\u001b[39;00m\n\u001b[1;32m    235\u001b[0m \n\u001b[1;32m    236\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[39m        Score function applied to prediction of estimator on X.\u001b[39;00m\n\u001b[1;32m    259\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 261\u001b[0m     y_pred \u001b[39m=\u001b[39m method_caller(estimator, \u001b[39m\"\u001b[39;49m\u001b[39mpredict\u001b[39;49m\u001b[39m\"\u001b[39;49m, X)\n\u001b[1;32m    262\u001b[0m     \u001b[39mif\u001b[39;00m sample_weight \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    263\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sign \u001b[39m*\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_score_func(\n\u001b[1;32m    264\u001b[0m             y_true, y_pred, sample_weight\u001b[39m=\u001b[39msample_weight, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_kwargs\n\u001b[1;32m    265\u001b[0m         )\n",
            "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/test_env/lib/python3.8/site-packages/sklearn/metrics/_scorer.py:71\u001b[0m, in \u001b[0;36m_cached_call\u001b[0;34m(cache, estimator, method, *args, **kwargs)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[39m\"\"\"Call estimator with method and args and kwargs.\"\"\"\u001b[39;00m\n\u001b[1;32m     70\u001b[0m \u001b[39mif\u001b[39;00m cache \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m---> 71\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mgetattr\u001b[39;49m(estimator, method)(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     73\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     74\u001b[0m     \u001b[39mreturn\u001b[39;00m cache[method]\n",
            "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/test_env/lib/python3.8/site-packages/skorch/classifier.py:208\u001b[0m, in \u001b[0;36mNeuralNetClassifier.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpredict\u001b[39m(\u001b[39mself\u001b[39m, X):\n\u001b[1;32m    179\u001b[0m     \u001b[39m\"\"\"Where applicable, return class labels for samples in X.\u001b[39;00m\n\u001b[1;32m    180\u001b[0m \n\u001b[1;32m    181\u001b[0m \u001b[39m    If the module's forward method returns multiple outputs as a\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    206\u001b[0m \n\u001b[1;32m    207\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 208\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpredict_proba(X)\u001b[39m.\u001b[39margmax(axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n",
            "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/test_env/lib/python3.8/site-packages/skorch/classifier.py:176\u001b[0m, in \u001b[0;36mNeuralNetClassifier.predict_proba\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[39m\"\"\"Where applicable, return probability estimates for\u001b[39;00m\n\u001b[1;32m    145\u001b[0m \u001b[39msamples.\u001b[39;00m\n\u001b[1;32m    146\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    172\u001b[0m \n\u001b[1;32m    173\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    174\u001b[0m \u001b[39m# Only the docstring changed from parent.\u001b[39;00m\n\u001b[1;32m    175\u001b[0m \u001b[39m# pylint: disable=useless-super-delegation\u001b[39;00m\n\u001b[0;32m--> 176\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mpredict_proba(X)\n",
            "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/test_env/lib/python3.8/site-packages/skorch/net.py:1436\u001b[0m, in \u001b[0;36mNeuralNet.predict_proba\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m   1434\u001b[0m     yp \u001b[39m=\u001b[39m yp[\u001b[39m0\u001b[39m] \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(yp, \u001b[39mtuple\u001b[39m) \u001b[39melse\u001b[39;00m yp\n\u001b[1;32m   1435\u001b[0m     yp \u001b[39m=\u001b[39m nonlin(yp)\n\u001b[0;32m-> 1436\u001b[0m     y_probas\u001b[39m.\u001b[39mappend(to_numpy(yp))\n\u001b[1;32m   1437\u001b[0m y_proba \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mconcatenate(y_probas, \u001b[39m0\u001b[39m)\n\u001b[1;32m   1438\u001b[0m \u001b[39mreturn\u001b[39;00m y_proba\n",
            "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/test_env/lib/python3.8/site-packages/skorch/utils.py:144\u001b[0m, in \u001b[0;36mto_numpy\u001b[0;34m(X)\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[39mif\u001b[39;00m X\u001b[39m.\u001b[39mrequires_grad:\n\u001b[1;32m    142\u001b[0m     X \u001b[39m=\u001b[39m X\u001b[39m.\u001b[39mdetach()\n\u001b[0;32m--> 144\u001b[0m \u001b[39mreturn\u001b[39;00m X\u001b[39m.\u001b[39;49mnumpy()\n",
            "\u001b[0;31mTypeError\u001b[0m: can't convert mps:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first."
          ]
        }
      ],
      "source": [
        "net.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m3aBRgNxXu-Y"
      },
      "source": [
        "## Prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dlS_-_-uXu-Y"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        },
        "id": "0mIomvowXu-Y",
        "outputId": "3fb5bbc6-b4be-4b62-af31-5023cd9087f3"
      },
      "outputs": [],
      "source": [
        "y_pred = net.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JS6w2oaWXu-Y"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.11297142857142857"
            ]
          },
          "execution_count": 85,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "accuracy_score(y_test, y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wnG3T_0IXu-Y"
      },
      "source": [
        "An accuracy of about 96% for a network with only one hidden layer is not too bad.\n",
        "\n",
        "Let's take a look at some predictions that went wrong:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OD5QIKXcXu-Y"
      },
      "outputs": [],
      "source": [
        "error_mask = y_pred != y_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hyOBeqXfXu-Y"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 5 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plot_example(X_test[error_mask], y_pred[error_mask])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-iqUP3z7Xu-Z"
      },
      "source": [
        "# Convolutional Network\n",
        "PyTorch expects a 4 dimensional tensor as input for its 2D convolution layer. The dimensions represent:\n",
        "* Batch size\n",
        "* Number of channel\n",
        "* Height\n",
        "* Width\n",
        "\n",
        "As initial batch size the number of examples needs to be provided. MNIST data has only one channel. As stated above, each MNIST vector represents a 28x28 pixel image. Hence, the resulting shape for PyTorch tensor needs to be (x, 1, 28, 28). "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eeEeLoAzXu-Z"
      },
      "outputs": [],
      "source": [
        "XCnn = X.reshape(-1, 1, 28, 28)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Fq-F-KzXu-Z",
        "outputId": "fcb3430d-9abf-4c2f-c14b-0dce3421c65c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(70000, 1, 28, 28)"
            ]
          },
          "execution_count": 89,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "XCnn.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gYEJSe8LXu-Z"
      },
      "outputs": [],
      "source": [
        "XCnn_train, XCnn_test, y_train, y_test = train_test_split(XCnn, y, test_size=0.25, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DL8Ecn60Xu-Z",
        "outputId": "57931d96-4418-4f0b-a336-1c9a10c0fd53"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((52500, 1, 28, 28), (52500,))"
            ]
          },
          "execution_count": 91,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "XCnn_train.shape, y_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-DYETvRLXu-b"
      },
      "outputs": [],
      "source": [
        "class Cnn(nn.Module):\n",
        "    def __init__(self, dropout=0.5):\n",
        "        super(Cnn, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3)\n",
        "        self.conv2_drop = nn.Dropout2d(p=dropout)\n",
        "        self.fc1 = nn.Linear(1600, 100) # 1600 = number channels * width * height\n",
        "        self.fc2 = nn.Linear(100, 10)\n",
        "        self.fc1_drop = nn.Dropout(p=dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(F.max_pool2d(self.conv1(x), 2))\n",
        "        x = torch.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
        "        \n",
        "        # flatten over channel, height and width = 1600\n",
        "        x = x.view(-1, x.size(1) * x.size(2) * x.size(3))\n",
        "        \n",
        "        x = torch.relu(self.fc1_drop(self.fc1(x)))\n",
        "        x = torch.softmax(self.fc2(x), dim=-1)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6OKSwz-uXu-b"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(0)\n",
        "\n",
        "cnn = NeuralNetClassifier(\n",
        "    Cnn,\n",
        "    max_epochs=10,\n",
        "    lr=0.002,\n",
        "    optimizer=torch.optim.Adam,\n",
        "    device=device,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tT1yCQu9Xu-c",
        "outputId": "a64d7c70-9fe6-42ad-e685-d56386d236d4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  epoch    train_loss    valid_acc    valid_loss      dur\n",
            "-------  ------------  -----------  ------------  -------\n",
            "      1        \u001b[36m2.3025\u001b[0m       \u001b[32m0.1124\u001b[0m        \u001b[35m2.3012\u001b[0m  61.2339\n",
            "      2        \u001b[36m2.3017\u001b[0m       0.1124        \u001b[35m2.3012\u001b[0m  44.9152\n",
            "      3        \u001b[36m2.3015\u001b[0m       0.1124        2.3012  50.8770\n",
            "      4        \u001b[36m2.3015\u001b[0m       0.1124        2.3012  43.4769\n",
            "      5        \u001b[36m2.3015\u001b[0m       0.1124        \u001b[35m2.3012\u001b[0m  54.4977\n",
            "      6        \u001b[36m2.3014\u001b[0m       0.1124        \u001b[35m2.3012\u001b[0m  39.4875\n",
            "      7        \u001b[36m2.3014\u001b[0m       0.1124        2.3012  40.5132\n",
            "      8        2.3014       0.1124        2.3012  46.1344\n",
            "      9        2.3014       0.1124        2.3012  43.7158\n",
            "     10        2.3014       0.1124        2.3012  47.0060\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<class 'skorch.classifier.NeuralNetClassifier'>[initialized](\n",
              "  module_=Cnn(\n",
              "    (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))\n",
              "    (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
              "    (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
              "    (fc1): Linear(in_features=1600, out_features=100, bias=True)\n",
              "    (fc2): Linear(in_features=100, out_features=10, bias=True)\n",
              "    (fc1_drop): Dropout(p=0.5, inplace=False)\n",
              "  ),\n",
              ")"
            ]
          },
          "execution_count": 94,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cnn.fit(XCnn_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dtZZJnttXu-c"
      },
      "outputs": [],
      "source": [
        "y_pred_cnn = cnn.predict(XCnn_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AxA4prLkXu-c",
        "outputId": "6c9d7bf9-e70e-4451-dae3-d31dd9bd1820"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.11297142857142857"
            ]
          },
          "execution_count": 96,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "accuracy_score(y_test, y_pred_cnn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-hUiQaw3Xu-c"
      },
      "source": [
        "An accuracy of >98% should suffice for this example!\n",
        "\n",
        "Let's see how we fare on the examples that went wrong before:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uj2UfRcZXu-c",
        "outputId": "3a109a81-205e-4f83-9a9e-1bce1fc93789"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.0"
            ]
          },
          "execution_count": 99,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "accuracy_score(y_test[error_mask], y_pred_cnn[error_mask])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OMq8yknZXu-c"
      },
      "source": [
        "Over 70% of the previously misclassified images are now correctly identified."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "id": "ujcNUygZXu-c",
        "outputId": "1f41152b-b7ed-4243-8ef0-4413f7f788d3"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 5 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plot_example(X_test[error_mask], y_pred_cnn[error_mask])"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.8.13 ('test_env')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "ad9e9eb2daee000098dbe82a593671e3359c3d84087040faff4d2ccf390e5b71"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
